{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44186c56",
   "metadata": {},
   "source": [
    "### Natural language processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34246a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install transformers torch spacy blis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2344875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk gensim spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2141aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Please add eggs, milk, and bread to my shopping list.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7daa8a",
   "metadata": {},
   "source": [
    "#### Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b726a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c717debc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text into sentences\n",
    "sentences = sent_tokenize(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d7dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c291e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punctuation removal\n",
    "import re\n",
    "\n",
    "# Remove punctuation characters\n",
    "text = re.sub(r\"[^a-zA-Z0-9]\", \" \", sentences[0]) \n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ff16b1",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce5030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9185e4cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = word_tokenize(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde2696a",
   "metadata": {},
   "source": [
    "#### Removal of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff38a405",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7c78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ebed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look at the stop words in nltk's corpus\n",
    "print(stopwords.words(\"spanish\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9b696b",
   "metadata": {},
   "source": [
    "#### Stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f0e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet') # download for lemmatization\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e9dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Reduce words to their stems\n",
    "stemmed = [PorterStemmer().stem(w) for w in words]\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1a818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# Reduce words to their root form\n",
    "lemmatized = [WordNetLemmatizer().lemmatize(w) for w in words]\n",
    "print(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another stemming and lemmatization example\n",
    "words2 = ['wait', 'waiting' , 'studies', 'studying', 'computers']\n",
    "\n",
    "# Stemming\n",
    "# Reduce words to their stems\n",
    "stemmed = [PorterStemmer().stem(w) for w in words2]\n",
    "print(\"Stemming output: {}\".format(stemmed))\n",
    "\n",
    "# Lemmatization\n",
    "# Reduce words to their root form\n",
    "lemmatized = [WordNetLemmatizer().lemmatize(w) for w in words2]\n",
    "print(\"Lemmatization output: {}\".format(lemmatized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900c5903",
   "metadata": {},
   "source": [
    "#### Part of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4145dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c95f4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186f3347",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tag each word with part of speech\n",
    "pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228ed682",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "POS\n",
    "\n",
    "CC: It is the conjunction of coordinating\n",
    "CD: It is a digit of cardinal\n",
    "DT: It is the determiner\n",
    "EX: Existential\n",
    "FW: It is a foreign word\n",
    "IN: Preposition and conjunction\n",
    "JJ: Adjective\n",
    "JJR and JJS: Adjective and superlative\n",
    "LS: List marker\n",
    "MD: Modal\n",
    "NN: Singular noun\n",
    "NNS, NNP, NNPS: Proper and plural noun\n",
    "PDT: Predeterminer\n",
    "WRB: Adverb of wh\n",
    "WP$: Possessive wh\n",
    "WP: Pronoun of wh\n",
    "WDT: Determiner of wp\n",
    "VBZ: Verb\n",
    "VBP, VBN, VBG, VBD, VB: Forms of verbs\n",
    "UH: Interjection\n",
    "TO: To go\n",
    "RP: Particle\n",
    "RBS, RB, RBR: Adverb\n",
    "PRP, PRP$: Pronoun personal and professional\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58040411",
   "metadata": {},
   "source": [
    "#### Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24e3832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'eggs': [ 8.1681199e-03 -4.4430327e-03  8.9854337e-03  8.2536647e-03\n",
      " -4.4352221e-03  3.0310510e-04  4.2744912e-03 -3.9263200e-03\n",
      " -5.5599655e-03 -6.5123225e-03 -6.7073823e-04 -2.9592158e-04\n",
      "  4.4630850e-03 -2.4740540e-03 -1.7260908e-04  2.4618758e-03\n",
      "  4.8675989e-03 -3.0808449e-05 -6.3394094e-03 -9.2608072e-03\n",
      "  2.6657581e-05  6.6618943e-03  1.4660227e-03 -8.9665223e-03\n",
      " -7.9386048e-03  6.5519023e-03 -3.7856805e-03  6.2549924e-03\n",
      " -6.6810320e-03  8.4796622e-03 -6.5163244e-03  3.2880199e-03\n",
      " -1.0569858e-03 -6.7875278e-03 -3.2875966e-03 -1.1614120e-03\n",
      " -5.4709399e-03 -1.2113475e-03 -7.5633135e-03  2.6466595e-03\n",
      "  9.0701487e-03 -2.3772502e-03 -9.7651005e-04  3.5135616e-03\n",
      "  8.6650876e-03 -5.9218528e-03 -6.8875779e-03 -2.9329848e-03\n",
      "  9.1476962e-03  8.6626766e-04 -8.6784009e-03 -1.4469790e-03\n",
      "  9.4794659e-03 -7.5494875e-03 -5.3580985e-03  9.3165627e-03\n",
      " -8.9737261e-03  3.8259076e-03  6.6544057e-04  6.6607012e-03\n",
      "  8.3127534e-03 -2.8507852e-03 -3.9923131e-03  8.8979173e-03\n",
      "  2.0896459e-03  6.2489416e-03 -9.4457148e-03  9.5901238e-03\n",
      " -1.3483083e-03 -6.0521150e-03  2.9925345e-03 -4.5661093e-04\n",
      "  4.7064926e-03 -2.2830211e-03 -4.1378425e-03  2.2778988e-03\n",
      "  8.3543835e-03 -4.9956059e-03  2.6686788e-03 -7.9905549e-03\n",
      " -6.7733466e-03 -4.6766878e-04 -8.7677278e-03  2.7894378e-03\n",
      "  1.5985954e-03 -2.3196924e-03  5.0037908e-03  9.7487867e-03\n",
      "  8.4542679e-03 -1.8802249e-03  2.0581519e-03 -4.0036892e-03\n",
      " -8.2414057e-03  6.2779556e-03 -1.9491815e-03 -6.6620467e-04\n",
      " -1.7713320e-03 -4.5356657e-03  4.0617096e-03 -4.2701806e-03]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Tokenize the sentence\n",
    "tokens = word_tokenize(text.lower())\n",
    "\n",
    "# Train a Word2Vec model (normally trained on a large corpus; here for demo purposes)\n",
    "model = Word2Vec([tokens], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "word_embedding = model.wv['eggs']\n",
    "print(\"Embedding for 'eggs':\", word_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a0e9c3",
   "metadata": {},
   "source": [
    "#### Contextual Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc16e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.1-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Downloading numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting packaging>=20.0 (from transformers)\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.9.11-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.1-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.66.6-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Downloading charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading transformers-4.46.1-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.1/10.0 MB 7.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.0/10.0 MB 7.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.8/10.0 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.2/10.0 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 8.3 MB/s eta 0:00:00\n",
      "Downloading torch-2.5.1-cp312-cp312-win_amd64.whl (203.0 MB)\n",
      "   ---------------------------------------- 0.0/203.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/203.0 MB 8.4 MB/s eta 0:00:24\n",
      "    --------------------------------------- 3.1/203.0 MB 7.4 MB/s eta 0:00:28\n",
      "    --------------------------------------- 5.0/203.0 MB 7.7 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 6.6/203.0 MB 7.7 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 8.4/203.0 MB 7.9 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 10.2/203.0 MB 8.1 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 11.8/203.0 MB 8.0 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 13.1/203.0 MB 7.8 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 14.7/203.0 MB 7.8 MB/s eta 0:00:25\n",
      "   --- ------------------------------------ 16.3/203.0 MB 7.5 MB/s eta 0:00:25\n",
      "   --- ------------------------------------ 17.8/203.0 MB 7.5 MB/s eta 0:00:25\n",
      "   --- ------------------------------------ 19.1/203.0 MB 7.4 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 20.7/203.0 MB 7.4 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 22.0/203.0 MB 7.3 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 23.3/203.0 MB 7.3 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 24.6/203.0 MB 7.2 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 26.0/203.0 MB 7.2 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 27.5/203.0 MB 7.1 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 28.8/203.0 MB 7.0 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 30.4/203.0 MB 7.0 MB/s eta 0:00:25\n",
      "   ------ --------------------------------- 31.5/203.0 MB 6.9 MB/s eta 0:00:25\n",
      "   ------ --------------------------------- 32.5/203.0 MB 6.8 MB/s eta 0:00:25\n",
      "   ------ --------------------------------- 33.6/203.0 MB 6.8 MB/s eta 0:00:25\n",
      "   ------ --------------------------------- 35.1/203.0 MB 6.8 MB/s eta 0:00:25\n",
      "   ------- -------------------------------- 36.2/203.0 MB 6.8 MB/s eta 0:00:25\n",
      "   ------- -------------------------------- 37.5/203.0 MB 6.7 MB/s eta 0:00:25\n",
      "   ------- -------------------------------- 39.1/203.0 MB 6.7 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 40.6/203.0 MB 6.7 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 41.9/203.0 MB 6.7 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 43.8/203.0 MB 6.7 MB/s eta 0:00:24\n",
      "   -------- ------------------------------- 45.1/203.0 MB 6.7 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 46.7/203.0 MB 6.8 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 48.2/203.0 MB 6.8 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 49.5/203.0 MB 6.8 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 50.6/203.0 MB 6.8 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 51.9/203.0 MB 6.7 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 53.5/203.0 MB 6.7 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 55.3/203.0 MB 6.7 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 56.6/203.0 MB 6.7 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 58.2/203.0 MB 6.7 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 59.8/203.0 MB 6.8 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 61.3/203.0 MB 6.8 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 62.4/203.0 MB 6.7 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 64.0/203.0 MB 6.8 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 65.3/203.0 MB 6.8 MB/s eta 0:00:21\n",
      "   ------------- -------------------------- 66.8/203.0 MB 6.8 MB/s eta 0:00:21\n",
      "   ------------- -------------------------- 68.7/203.0 MB 6.8 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 70.3/203.0 MB 6.8 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 71.6/203.0 MB 6.8 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 73.4/203.0 MB 6.8 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 75.0/203.0 MB 6.8 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 76.5/203.0 MB 6.8 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 77.9/203.0 MB 6.8 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 79.2/203.0 MB 6.8 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 80.7/203.0 MB 6.8 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 82.1/203.0 MB 6.8 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 83.6/203.0 MB 6.8 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 84.9/203.0 MB 6.8 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 86.2/203.0 MB 6.8 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 88.1/203.0 MB 6.8 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 89.4/203.0 MB 6.8 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 91.0/203.0 MB 6.8 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 92.0/203.0 MB 6.8 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 93.6/203.0 MB 6.8 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 95.2/203.0 MB 6.8 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 96.7/203.0 MB 6.8 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 98.6/203.0 MB 6.8 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 99.9/203.0 MB 6.8 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 101.4/203.0 MB 6.8 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 103.0/203.0 MB 6.8 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 104.9/203.0 MB 6.9 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 106.2/203.0 MB 6.8 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 107.2/203.0 MB 6.8 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 108.5/203.0 MB 6.8 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 110.1/203.0 MB 6.8 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 111.7/203.0 MB 6.8 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 113.0/203.0 MB 6.8 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 114.6/203.0 MB 6.8 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 115.9/203.0 MB 6.8 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 117.2/203.0 MB 6.8 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 118.5/203.0 MB 6.8 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 119.8/203.0 MB 6.8 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 121.6/203.0 MB 6.8 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 123.2/203.0 MB 6.8 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 124.5/203.0 MB 6.8 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 126.1/203.0 MB 6.8 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 127.4/203.0 MB 6.8 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 129.0/203.0 MB 6.8 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 130.3/203.0 MB 6.8 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 131.6/203.0 MB 6.8 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 132.9/203.0 MB 6.8 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 134.5/203.0 MB 6.8 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 136.1/203.0 MB 6.8 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 137.6/203.0 MB 6.8 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 138.9/203.0 MB 6.8 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 140.5/203.0 MB 6.8 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 141.8/203.0 MB 6.8 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 143.4/203.0 MB 6.8 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 145.0/203.0 MB 6.8 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 146.3/203.0 MB 6.8 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 147.6/203.0 MB 6.8 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 149.2/203.0 MB 6.8 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 150.7/203.0 MB 6.8 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 152.3/203.0 MB 6.8 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 153.6/203.0 MB 6.8 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 155.5/203.0 MB 6.8 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 157.0/203.0 MB 6.8 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 158.6/203.0 MB 6.8 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 159.9/203.0 MB 6.8 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 161.5/203.0 MB 6.8 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 162.8/203.0 MB 6.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 164.1/203.0 MB 6.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 165.2/203.0 MB 6.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 166.5/203.0 MB 6.8 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 167.8/203.0 MB 6.8 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 169.3/203.0 MB 6.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 170.7/203.0 MB 6.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 172.2/203.0 MB 6.8 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 173.3/203.0 MB 6.8 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 174.9/203.0 MB 6.8 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 176.4/203.0 MB 6.8 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 178.0/203.0 MB 6.8 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 179.3/203.0 MB 6.8 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 180.4/203.0 MB 6.7 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 181.9/203.0 MB 6.7 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 183.0/203.0 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 184.5/203.0 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 185.9/203.0 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 186.9/203.0 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 188.5/203.0 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 189.5/203.0 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 190.6/203.0 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 191.9/203.0 MB 6.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 193.5/203.0 MB 6.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 195.0/203.0 MB 6.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 196.1/203.0 MB 6.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 197.4/203.0 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.4/203.0 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.8/203.0 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  200.8/203.0 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.1/203.0 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 203.0/203.0 MB 6.5 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.3/6.2 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.6/6.2 MB 5.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.2/6.2 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.5/6.2 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 6.1 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading numpy-2.1.3-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 5.2 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.9/12.6 MB 6.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.5/12.6 MB 6.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.3/12.6 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.9/12.6 MB 7.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 7.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.5/12.6 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.8/12.6 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 6.7 MB/s eta 0:00:00\n",
      "Downloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Using cached regex-2024.9.11-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Downloading safetensors-0.4.5-cp312-none-win_amd64.whl (286 kB)\n",
      "Downloading tokenizers-0.20.1-cp312-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 1.3/2.4 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 5.0 MB/s eta 0:00:00\n",
      "Using cached tqdm-4.66.6-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 1.0/1.7 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 4.7 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Installing collected packages: mpmath, urllib3, typing-extensions, tqdm, sympy, safetensors, regex, pyyaml, packaging, numpy, networkx, idna, fsspec, filelock, charset-normalizer, certifi, torch, requests, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed certifi-2024.8.30 charset-normalizer-3.4.0 filelock-3.16.1 fsspec-2024.10.0 huggingface-hub-0.26.2 idna-3.10 mpmath-1.3.0 networkx-3.4.2 numpy-2.1.3 packaging-24.1 pyyaml-6.0.2 regex-2024.9.11 requests-2.32.3 safetensors-0.4.5 sympy-1.13.1 tokenizers-0.20.1 torch-2.5.1 tqdm-4.66.6 transformers-4.46.1 typing-extensions-4.12.2 urllib3-2.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install transformers torch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertModel\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load the BERT tokenizer and model\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load the BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize and encode the text\n",
    "text = \"Climate change affects coral reefs.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Pass the inputs through BERT to get embeddings\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Extract the embeddings for each token\n",
    "embeddings = outputs.last_hidden_state  # Shape: [1, sequence_length, hidden_size]\n",
    "print(\"Shape of embeddings:\", embeddings.shape)\n",
    "\n",
    "# Get the embedding for the word \"coral\"\n",
    "token_id = tokenizer.convert_tokens_to_ids(\"coral\")\n",
    "coral_embedding = embeddings[0, inputs['input_ids'][0].tolist().index(token_id)]\n",
    "print(\"Embedding for 'coral':\", coral_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a8864b",
   "metadata": {},
   "source": [
    "#### Named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b1bb436",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "BLIS support requires blis: pip install blis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the pre-trained SpaCy model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Iterable, Union\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# set library-specific custom warning handling before doing anything else\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_default_warnings\n\u001b[0;32m      8\u001b[0m setup_default_warnings()  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\errors.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mErrorsWithCodes\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, code):\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\compat.py:39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatalogue\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _importlib_metadata \u001b[38;5;28;01mas\u001b[39;00m importlib_metadata  \u001b[38;5;66;03m# type: ignore[no-redef]    # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optimizer  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     41\u001b[0m pickle \u001b[38;5;241m=\u001b[39m pickle\n\u001b[0;32m     42\u001b[0m copy_reg \u001b[38;5;241m=\u001b[39m copy_reg\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\api.py:23\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config, ConfigValidationError, registry\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minitializers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m     configure_normal_init,\n\u001b[0;32m     18\u001b[0m     glorot_uniform_init,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     zero_init,\n\u001b[0;32m     22\u001b[0m )\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     LSTM,\n\u001b[0;32m     25\u001b[0m     CauchySimilarity,\n\u001b[0;32m     26\u001b[0m     ClippedLinear,\n\u001b[0;32m     27\u001b[0m     Dish,\n\u001b[0;32m     28\u001b[0m     Dropout,\n\u001b[0;32m     29\u001b[0m     Embed,\n\u001b[0;32m     30\u001b[0m     Gelu,\n\u001b[0;32m     31\u001b[0m     HardSigmoid,\n\u001b[0;32m     32\u001b[0m     HardSwish,\n\u001b[0;32m     33\u001b[0m     HardSwishMobilenet,\n\u001b[0;32m     34\u001b[0m     HardTanh,\n\u001b[0;32m     35\u001b[0m     HashEmbed,\n\u001b[0;32m     36\u001b[0m     LayerNorm,\n\u001b[0;32m     37\u001b[0m     Linear,\n\u001b[0;32m     38\u001b[0m     Logistic,\n\u001b[0;32m     39\u001b[0m     Maxout,\n\u001b[0;32m     40\u001b[0m     Mish,\n\u001b[0;32m     41\u001b[0m     MultiSoftmax,\n\u001b[0;32m     42\u001b[0m     MXNetWrapper,\n\u001b[0;32m     43\u001b[0m     ParametricAttention,\n\u001b[0;32m     44\u001b[0m     ParametricAttention_v2,\n\u001b[0;32m     45\u001b[0m     PyTorchLSTM,\n\u001b[0;32m     46\u001b[0m     PyTorchRNNWrapper,\n\u001b[0;32m     47\u001b[0m     PyTorchWrapper,\n\u001b[0;32m     48\u001b[0m     PyTorchWrapper_v2,\n\u001b[0;32m     49\u001b[0m     PyTorchWrapper_v3,\n\u001b[0;32m     50\u001b[0m     Relu,\n\u001b[0;32m     51\u001b[0m     ReluK,\n\u001b[0;32m     52\u001b[0m     Sigmoid,\n\u001b[0;32m     53\u001b[0m     Softmax,\n\u001b[0;32m     54\u001b[0m     Softmax_v2,\n\u001b[0;32m     55\u001b[0m     SparseLinear,\n\u001b[0;32m     56\u001b[0m     SparseLinear_v2,\n\u001b[0;32m     57\u001b[0m     Swish,\n\u001b[0;32m     58\u001b[0m     TensorFlowWrapper,\n\u001b[0;32m     59\u001b[0m     TorchScriptWrapper_v1,\n\u001b[0;32m     60\u001b[0m     add,\n\u001b[0;32m     61\u001b[0m     array_getitem,\n\u001b[0;32m     62\u001b[0m     bidirectional,\n\u001b[0;32m     63\u001b[0m     chain,\n\u001b[0;32m     64\u001b[0m     clone,\n\u001b[0;32m     65\u001b[0m     concatenate,\n\u001b[0;32m     66\u001b[0m     expand_window,\n\u001b[0;32m     67\u001b[0m     keras_subclass,\n\u001b[0;32m     68\u001b[0m     list2array,\n\u001b[0;32m     69\u001b[0m     list2padded,\n\u001b[0;32m     70\u001b[0m     list2ragged,\n\u001b[0;32m     71\u001b[0m     map_list,\n\u001b[0;32m     72\u001b[0m     noop,\n\u001b[0;32m     73\u001b[0m     padded2list,\n\u001b[0;32m     74\u001b[0m     premap_ids,\n\u001b[0;32m     75\u001b[0m     pytorch_to_torchscript_wrapper,\n\u001b[0;32m     76\u001b[0m     ragged2list,\n\u001b[0;32m     77\u001b[0m     reduce_first,\n\u001b[0;32m     78\u001b[0m     reduce_last,\n\u001b[0;32m     79\u001b[0m     reduce_max,\n\u001b[0;32m     80\u001b[0m     reduce_mean,\n\u001b[0;32m     81\u001b[0m     reduce_sum,\n\u001b[0;32m     82\u001b[0m     remap_ids,\n\u001b[0;32m     83\u001b[0m     remap_ids_v2,\n\u001b[0;32m     84\u001b[0m     residual,\n\u001b[0;32m     85\u001b[0m     resizable,\n\u001b[0;32m     86\u001b[0m     siamese,\n\u001b[0;32m     87\u001b[0m     sigmoid_activation,\n\u001b[0;32m     88\u001b[0m     softmax_activation,\n\u001b[0;32m     89\u001b[0m     strings2arrays,\n\u001b[0;32m     90\u001b[0m     tuplify,\n\u001b[0;32m     91\u001b[0m     uniqued,\n\u001b[0;32m     92\u001b[0m     with_array,\n\u001b[0;32m     93\u001b[0m     with_array2d,\n\u001b[0;32m     94\u001b[0m     with_cpu,\n\u001b[0;32m     95\u001b[0m     with_debug,\n\u001b[0;32m     96\u001b[0m     with_flatten,\n\u001b[0;32m     97\u001b[0m     with_flatten_v2,\n\u001b[0;32m     98\u001b[0m     with_getitem,\n\u001b[0;32m     99\u001b[0m     with_list,\n\u001b[0;32m    100\u001b[0m     with_nvtx_range,\n\u001b[0;32m    101\u001b[0m     with_padded,\n\u001b[0;32m    102\u001b[0m     with_ragged,\n\u001b[0;32m    103\u001b[0m     with_reshape,\n\u001b[0;32m    104\u001b[0m     with_signpost_interval,\n\u001b[0;32m    105\u001b[0m )\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    107\u001b[0m     CategoricalCrossentropy,\n\u001b[0;32m    108\u001b[0m     CosineDistance,\n\u001b[0;32m    109\u001b[0m     L2Distance,\n\u001b[0;32m    110\u001b[0m     SequenceCategoricalCrossentropy,\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    113\u001b[0m     Model,\n\u001b[0;32m    114\u001b[0m     change_attr_values,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m     wrap_model_recursive,\n\u001b[0;32m    119\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\__init__.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclipped_linear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClippedLinear, HardSigmoid, HardTanh, ReluK\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclone\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcatenate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concatenate\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdish\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dish\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdropout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dropout\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\concatenate.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_width\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnoop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m noop\n\u001b[1;32m---> 21\u001b[0m NUMPY_OPS \u001b[38;5;241m=\u001b[39m \u001b[43mNumpyOps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m InT \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInT\u001b[39m\u001b[38;5;124m\"\u001b[39m, bound\u001b[38;5;241m=\u001b[39mAny)\n\u001b[0;32m     25\u001b[0m OutT \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutT\u001b[39m\u001b[38;5;124m\"\u001b[39m, bound\u001b[38;5;241m=\u001b[39mUnion[Array2d, Sequence[Array2d], Ragged])\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\backends\\numpy_ops.pyx:63\u001b[0m, in \u001b[0;36mthinc.backends.numpy_ops.NumpyOps.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: BLIS support requires blis: pip install blis"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the pre-trained SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define your text\n",
    "text = \"Apple is looking at buying a startup in San Francisco for $1 billion.\"\n",
    "\n",
    "# Process the text with the SpaCy model\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract and display named entities\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab0468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df5a63a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f49e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd392f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042eaf5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb5d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1f5ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f8bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640818b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373f8779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0893d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beff7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b206f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4210b415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e614f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
